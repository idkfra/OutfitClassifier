# -*- coding: utf-8 -*-
"""testModelli.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13j68M2m-c1TZzpNEYoXg-51zWS-Rbrn7
"""

import pandas as pd
dataset = pd.read_csv("datasetCorretto.csv")

dataset

"""Iniziamo a testare diversi modelli, per valutare quale abbia una accuracy e precision migliore

"""

from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score

from sklearn.metrics import precision_score

encoded_dataset = dataset.copy()

encoder = LabelEncoder()

# Codifica delle variabili categoriche
for column in encoded_dataset.columns:
    if encoded_dataset[column].dtype == 'object':  # Controllo se la colonna è di tipo 'object' (stringa)
        encoded_dataset[column] = encoder.fit_transform(encoded_dataset[column])

# Dividere il dataset in variabili indipendenti (features) e variabile target
X = encoded_dataset[['Stagione', 'Occasione', 'Tipo abbigliamento', 'Sesso', 'Colore1', 'Colore2', 'Top_outfit', 'Bottom_outfit']]
y = encoded_dataset['Comfort o stile?']

# Suddivisione dei dati in set di addestramento e test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=32)

# Creazione e addestramento del modello Naive Bayes
model = GaussianNB()
model.fit(X_train, y_train)

# Predizione dei risultati
y_pred = model.predict(X_test)

# Valutazione delle prestazioni del modello
accuracy = accuracy_score(y_test, y_pred)
recall = recall_score(y_test, y_pred, pos_label=0)
precision = precision_score(y_test, y_pred, pos_label=0)

print(f"Accuracy del modello Gaussian Naive Bayas sul test set: {accuracy:.9f}")
print(f"Precison del modello Gaussian Naive Bayas sul test set: {precision:.9f}")
print(f"Recall del modello Gaussian Naive Bayas sul test set: {recall:.9f}")

"""Modello Bernoulli"""

from sklearn.naive_bayes import BernoulliNB
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score
from sklearn.metrics import recall_score

from sklearn.metrics import precision_score

# Copia il tuo dataset in un nuovo DataFrame (facoltativo, ma consigliato per mantenere il dataset originale intatto)
encoded_dataset = dataset.copy()

# Inizializza il LabelEncoder
encoder = LabelEncoder()

# Codifica delle variabili categoriche
for column in encoded_dataset.columns:
    if encoded_dataset[column].dtype == 'object':  # Controlla se la colonna è di tipo 'object' (stringa)
        encoded_dataset[column] = encoder.fit_transform(encoded_dataset[column])

# Dividi il dataset in variabili indipendenti (features) e variabile target
X = encoded_dataset[['Stagione', 'Occasione', 'Tipo abbigliamento', 'Sesso', 'Colore1', 'Colore2', 'Top_outfit', 'Bottom_outfit']]
y = encoded_dataset['Comfort o stile?']

# Suddivisione dei dati in set di addestramento e test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Creazione e addestramento del modello Naive Bayes
model = BernoulliNB()
model.fit(X_train, y_train)

# Predizione dei risultati
y_pred = model.predict(X_test)

# Valutazione delle prestazioni del modello
accuracy = accuracy_score(y_test, y_pred)
recall = recall_score(y_test, y_pred, pos_label=0)
precision = precision_score(y_test, y_pred, pos_label=0)

print(f"Accuracy del modello Bernoulli Naive Bayas sul test set: {accuracy:.9f}")
print(f"Precison del modello Bernoulli Naive Bayas sul test set: {precision:.9f}")
print(f"Recall del modello Bernoulli Naive Bayas sul test set: {recall:.9f}")

"""modello DecisionTree"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score

from sklearn.preprocessing import OneHotEncoder

# Separiamo i nostri dati in dati di training e dati di test
X = encoded_dataset[['Stagione', 'Occasione', 'Tipo abbigliamento', 'Sesso', 'Colore1', 'Colore2', 'Top_outfit', 'Bottom_outfit']]
y = encoded_dataset['Comfort o stile?']

encoder = OneHotEncoder()
X_encoded = encoder.fit_transform(X)

X_encoded
# Specifichiamo la proporzione fra i due con test_size; in questo caso abbiamo impostato il training set al 80% e il test set al 20%
X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.1, random_state=42)

# Utilizziamo il training set per addestrare il modello
model = DecisionTreeClassifier()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

# Valutazione delle prestazioni del modello
accuracy = accuracy_score(y_test, y_pred)
precision= precision_score(y_test, y_pred, pos_label='Stile')
recall = recall_score(y_test, y_pred, pos_label='Stile')

print("Accuracy del modello DecisionTreeClassifier:", accuracy)
print("Precision del modello DecisionTreeClassifier:", precision)
print("Recall del modello DecisionTreeClassifier:", recall)

"""modello SVC"""

from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, precision_score, recall_score

encoded_dataset = dataset.copy()

# Codifica delle variabili categoriche
encoder = LabelEncoder()
encoded_dataset['Stagione'] = encoder.fit_transform(encoded_dataset['Stagione'])
encoded_dataset['Occasione'] = encoder.fit_transform(encoded_dataset['Occasione'])
encoded_dataset['Tipo abbigliamento'] = encoder.fit_transform(encoded_dataset['Tipo abbigliamento'])
encoded_dataset['Sesso'] = encoder.fit_transform(encoded_dataset['Sesso'])
encoded_dataset['Colore1'] = encoder.fit_transform(encoded_dataset['Colore1'])
encoded_dataset['Colore2'] = encoder.fit_transform(encoded_dataset['Colore2'])
encoded_dataset['Top_outfit'] = encoder.fit_transform(encoded_dataset['Top_outfit'])
encoded_dataset['Bottom_outfit'] = encoder.fit_transform(encoded_dataset['Bottom_outfit'])

# Dividi il dataset in variabili indipendenti (X) e variabile target (y)
X = encoded_dataset[['Stagione', 'Occasione', 'Tipo abbigliamento', 'Sesso', 'Colore1', 'Colore2', 'Top_outfit', 'Bottom_outfit']]
y = encoded_dataset['Comfort o stile?']

# Suddivisione dei dati in set di addestramento e test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Creazione e addestramento del modello
model = SVC(kernel='linear', random_state=42)  # Specifica il kernel (lineare, RBF, polinomiale, ecc.)
model.fit(X_train, y_train)

# Predizione dei risultati
y_pred = model.predict(X_test)

# Valutazione delle prestazioni del modello
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, pos_label='Stile')

recall = recall_score(y_test, y_pred, pos_label='Stile')
print(f"Accuracy del modello SVC sul test set: {accuracy:.9f}")
print(f"Recall del modello SVC sul test set: {recall:.9f}")
print(f"Precison del modello SVC sul test set: {precision:.9f}")

"""L'ExtraTreesClassifier è una variante dell'algoritmo Random Forest che introduce ulteriore casualità durante la creazione dei singoli alberi decisionali, rendendoli "più estremi" rispetto ai singoli alberi di un Random Forest tradizionale."""

from sklearn.ensemble import ExtraTreesClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder


X = encoded_dataset[['Stagione', 'Occasione', 'Tipo abbigliamento', 'Sesso', 'Colore1', 'Colore2', 'Top_outfit', 'Bottom_outfit']]
y = encoded_dataset['Comfort o stile?']

encoder = OneHotEncoder()
X_encoded = encoder.fit_transform(X)

X_encoded

# Suddivisione dei dati in set di addestramento e test
X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=42)

# Creazione e addestramento del modello Extra Trees
et_model = ExtraTreesClassifier(random_state=32)
et_model.fit(X_train, y_train)

# Predizione dei risultati
y_pred_et = et_model.predict(X_test)

# Valutazione delle prestazioni del modello
accuracy_et = accuracy_score(y_test, y_pred_et)
recall_et = recall_score(y_test, y_pred_et, pos_label='Stile')
precision_et = precision_score(y_test, y_pred_et, pos_label='Stile')

print(f"Accuracy del modello Extra Trees sul test set: {accuracy_et:.9f}")
print(f"Precison del modello Extra Trees sul test set: {precision_et:.9f}")
print(f"Recall del modello Extra Trees sul test set: {recall_et:.9f}")

"""Di seguito viene riportato l'addestramento con il LinearSVC"""

from sklearn.svm import LinearSVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, recall_score, precision_score
from sklearn.preprocessing import LabelEncoder

# Copia il tuo dataset in un nuovo DataFrame (facoltativo, ma consigliato per mantenere il dataset originale intatto)
from sklearn.preprocessing import OneHotEncoder


X = encoded_dataset[['Stagione', 'Occasione', 'Tipo abbigliamento', 'Sesso', 'Colore1', 'Colore2', 'Top_outfit', 'Bottom_outfit']]
y = encoded_dataset['Comfort o stile?']

encoder = OneHotEncoder()
X_encoded = encoder.fit_transform(X)

X_encoded


# Suddivisione dei dati in set di addestramento e test
X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=42)

# Creazione e addestramento del modello Linear SVC
svc_model = LinearSVC(random_state=32)
svc_model.fit(X_train, y_train)

# Predizione dei risultati
y_pred_svc = svc_model.predict(X_test)

# Valutazione delle prestazioni del modello
accuracy_svc = accuracy_score(y_test, y_pred_svc)
recall_svc = recall_score(y_test, y_pred_svc, pos_label='Stile')
precision_svc = precision_score(y_test, y_pred_svc, pos_label='Stile')

print(f"Accuracy del modello Linear SVC sul test set: {accuracy_svc:.9f}")
print(f"Precison del modello Linear SVC sul test set: {precision_svc:.9f}")
print(f"Recall del modello Linear SVC sul test set: {recall_svc:.9f}")

"""Di seguito è riportato l'addestramento tramite il MultinominalNB"""

from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, recall_score, precision_score
from sklearn.preprocessing import OneHotEncoder


# Dividi il dataset in variabili indipendenti (features) e variabile target
X = encoded_dataset[['Stagione', 'Occasione', 'Tipo abbigliamento', 'Sesso', 'Colore1', 'Colore2', 'Top_outfit', 'Bottom_outfit']]
y = encoded_dataset['Comfort o stile?']


encoder = OneHotEncoder()
X_encoded = encoder.fit_transform(X)

X_encoded

# Suddivisione dei dati in set di addestramento e test
X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=42)

# Creazione e addestramento del modello Multinomial Naive Bayes
mnb_model = MultinomialNB()
mnb_model.fit(X_train, y_train)

# Predizione dei risultati
y_pred_mnb = mnb_model.predict(X_test)

# Valutazione delle prestazioni del modello
accuracy_mnb = accuracy_score(y_test, y_pred_mnb)
recall_mnb = recall_score(y_test, y_pred_mnb, pos_label='Stile')
precision_mnb = precision_score(y_test, y_pred_mnb, pos_label='Stile')

print(f"Accuracy del modello Multinomial Naive Bayes sul test set: {accuracy_mnb:.9f}")
print(f"Precison del modello Multinomial Naive Bayes sul test set: {precision_mnb:.9f}")
print(f"Recall del modello Multinomial Naive Bayes sul test set: {recall_mnb:.9f}")

"""Infine, utilizziamo una variante del Random Forest Classifier:"""

from sklearn.preprocessing import OneHotEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score

# Separiamo le variabili indipendenti da quella che vogliamo predire
X = dataset[['Stagione', 'Occasione', 'Tipo abbigliamento', 'Sesso', 'Colore1', 'Colore2', 'Top_outfit', 'Bottom_outfit']]
y = dataset['Comfort o stile?']


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


encoder = OneHotEncoder()
X_train_encoded = encoder.fit_transform(X_train)
X_test_encoded = encoder.transform(X_test)


model = RandomForestClassifier(n_estimators=40, criterion='gini', max_depth=None, min_samples_split=2, random_state=32)
model.fit(X_train_encoded, y_train)

# Predizione sui dati di test
y_pred = model.predict(X_test_encoded)

# Valutazione delle prestazioni del modello
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred, pos_label='Stile')
recall = recall_score(y_test, y_pred, pos_label='Stile')
print(f"Accuracy del modello Random Forest Extra Trees Classifier sul test set: {accuracy:.9f}")
print(f"Precison del modello Random Forest Extra Trees Classifier sul test set: {precision:.9f}")
print(f"Recall del modello Random Forest Extra Trees Classifier sul test set: {recall:.9f}")